# Understanding Tokens in ChatGPT

Token是 ChatGPT 和其他类似语言模型（例如 GPT-3.5）中文本的基本单位。它们在测量输入和输出文本的长度、确定计费成本以及确保您的对话符合模型的限制方面发挥着关键作用。在本文中，我们将深入研究Token的世界，并探讨它们如何影响您与 ChatGPT 的交互。

## 什么是Token

在 ChatGPT 等语言模型的上下文中，Token可以被视为文本单元。它可以短至一个字符，也可以长至一个英文单词。但是，标记化取决于语言，并且标记长度在其他语言中可能会有所不同。让我们用一个例子来说明这一点：

考虑这句话: “ChatGPT is great!”

这句话被编码为六个标记：[“Chat”、“G”、“PT”、“is”、“great”、“!”]。细分如下：

“Chat” 是一个token。

“G”是一个token。

“PT”是一个token。

“is”（带有前导空格）是一个token。

“great”（带有前导空格）是一个token。

“！”是一个token。

标记不仅可以包含单词，还可以包含标点符号和空格，这可能会影响您在给定文本中对它们进行计数的方式。

使用 ChatGPT 时，计算Token至关重要。出于各种原因，您需要了解输入和输出中的token数量，包括计费和保持在模型的Token限制内。以下是计算Token的方法：

使用库：OpenAI 提供了一个名为 Tiktoken 的 Python 库，它允许您在不调用 API 的情况下计算文本字符串中的标记。您可以在 GitHub 上找到该库并使用它来分析文本的标记计数。

API 响应：当您对 ChatGPT 进行 API 调用时，API 响应包含一个使用字段，告诉您请求中使用了多少Token。此信息可帮助您跟踪您的Token消耗情况。

## Input and Output Tokens 输入和输出Token

输入（您的提示或对话历史记录）和输出（模型的响应）Token都会计入您的Token使用量。例如，如果您的输入消息使用 10 个Token，并且模型的响应生成额外的 15 个Token，则您将总共需要支付 25 个Token。

## Token限额

ChatGPT 模型有最大Token限制，对于 GPT-3.5 模型，通常约为 4096 个Token。此限制意味着，如果您的对话超过此Token计数，您将需要截断或省略部分文本以使其适合。从输入中删除消息时要小心，因为模型会丢失它们的所有知识。

## 计费

您对Token的使用直接影响使用 ChatGPT 的成本。您需要根据 API 调用中使用的Token总数来计费。使用更多Token进行更长时间的对话将产生更高的成本。因此，有效管理Token使用以控制费用至关重要。

## 管理Token使用

从对话中删除不太相关或较旧的消息，同时保留模型生成有意义的响应所需的上下文。

较短的文本：保持您的消息简洁明了，以减少Token消耗。

系统消息：使用“[SUMMARIZE]”等系统级指令来指导模型生成响应的行为。

## 特殊token

某些Token在 ChatGPT 中具有特殊用途。例如，“\n”标记表示对话中的新消息，帮助模型区分不同的消息。系统级指令，例如“[SUMMARIZE]”，也被编码为Token，并且可以影响模型的行为。

要进一步探索标记化，您可以使用交互式工具 Tokenizer tool，它允许您计算标记的数量并查看文本如何分解为标记。

总之，标记是 ChatGPT 和类似语言模型中文本的构建块。了解Token的工作原理、准确计数并管理其使用对于控制成本并确保您的对话保持在模型的Token限制内至关重要。当您浏览人工智能生成的文本世界时，请记住标记作为测量和交互的基本单位。

> https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them

# 什么是Token以及如何计算Token

Token可以被认为是单词的片段。在 API 处理请求之前，输入会被分解为Token。这些标记并未准确地在单词开始或结束的位置进行切割 - 标记可以包含尾随空格甚至子单词。以下是一些帮助理解Token长度的有用经验规则：

- 1 token ~= 4 chars in English
- 1 token ~= ¾ words
- 100 tokens ~= 75 words
或者
- 1-2 sentence ~= 30 tokens
- 1 paragraph ~= 100 tokens
- 1,500 words ~= 2048 tokens

