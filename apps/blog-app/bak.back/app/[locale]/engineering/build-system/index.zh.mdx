# Build System

Build system 指的是自动化执行一系列可重复任务的软件系统，常见的有 Make、Shake、Bazel，他们以源文件作为输入，根据任务描述文件（比如：makefile）执行任务，构建出可执行文件。

由此我们可以看出一些通用的概念：

- Task：任务，实际的逻辑由任务的描述（task descriptor）所定义，比如 makefile、Excel 的公式。

- Input：任务输入。

- Output：任务输出，任务的输出可能是下一个任务的输入。

- Info：构建信息，跨构建的信息，供下次构建使用，比如 Make 中文件的修改时间就是它的 Info，可以理解为 bundler 中的缓存。

- Store：存储，存储 Task 的 Input 和 Output 以及 Info 的地方，比如在 Make 中文件系统就是它的 Store。

- Build：构建，依据上述的概念我们可以将一次构建看作：根据定义的 Tasks 和原有的 Store，输入新的 Inputs，获得新的 Store。

这些概念是很通用的，在各个 build system 中的实现也比较相似，并不是造成不同 build systems 的主要原因，各个 build systems 不同的主要原因其实是对于以下两点所选取的策略不同导致的：

- Task 是否重新执行。

- Tasks 的执行顺序。

这两点分别对应两个比较重要的概念：Rebuilder 和 Scheduler，不同 build systems 可以看做使用了不同 Rebuilder 和不同 Scheduler 的组合。

### Scheduler

持有 Rebuilder，进行一次新的 Build，决定了以怎样的顺序执行 Tasks。

### Rebuilder

持有 Task，对 Task 进行重新执行，决定了 Task 是否需要重新执行，是使用缓存还是重新执行的结果。

### Build systems

build systems 可以看做使用了不同 Rebuilder 和不同 Scheduler 的组合。

先介绍几个常见的特性：

- Dynamic dependencies：Task 依赖的 Tasks 是静态声明的还是动态计算出的，比如 makefile 就静态声明了各个 Task 间的依赖关系，Excel 的 IF (RANDBETWEEN (0, 1) > 0.5, A1, A2) 就需要动态计算出 B2 的依赖。

- Minimality：仅执行最少的任务完成构建，当然最小是很难达到的，所以这个特性往往是相对的。

- Early cutoff：Task 重新执行时 Output 没发生改变时，依赖该 Task 的 Tasks 能否停止执行，提前完成构建。

### Make

make = topological modTimeRebuilder

Make 使用 makefile 来描述任务，这些任务间的依赖关系明确，属于静态依赖，也不支持循环依赖，所以 Make 使用了 topological scheduler 以拓扑顺序执行任务。

Make 的 Info 构建信息其实就是文件系统本身，文件系统会有文件修改时间，Make 通过文件修改时间来判断任务是否需要重新执行，如果文件的修改时间早于其依赖文件的修改时间，则说明该任务需要重新执行，Make 将文件修改时间当做 dirty bit，属于 dirty bit rebuilder 的一种。

当然很多情况下文件修改时间是不可信的，比如有些程序会更新文件修改时间，但文件实际内容并不会修改，这就导致任务没必要的重新执行。

Make 通过 modTimeRebuilder 实现 Minimality，跳过不需要执行的任务，但也因为 modTimeRebuilder 导致它没有实现 Early cutoff，因为任务重新执行后输出的新的文件，尽管内容没变，文件修改时间也是改变的，导致不能提前中断，从这里也可以看出，没有实现 Early cutoff 的执行的任务一定不是最少的，所以 Minimality 往往是相对的。

### Bazel

bazel = restarting ctRebuilder

Bazel 也使用了 restarting scheduler 来执行任务，Bazel 也有一套优化机制来避免 restarting 的开销。

Bazel 使用 ctRebuilder 支持了云缓存和远程执行任务。

### Shake

shake = suspending vtRebuilder

Shake 使用 vtRebuilder，在任务执行时追踪任务的依赖，并记录下来，在下次执行时，如果依赖没发生改变，则跳过执行，并且如果当前任务没被执行，则依赖当前任务的任务由于依赖没发生改变，也不需要执行，以此实现 Minimality 和 Early cutoff。

Shake 由于是任务执行时追踪依赖，并不需要提前静态定义，所以也支持 Dynamic dependencies。

### Bundlers

Bundler 其实可以理解为 build system + 一部分 task descriptor，build system 其实对任务具体做什么并不关心，任务具体做什么由用户通过任务描述文件提供，build system 只管执行任务。

早期 gulp、grunt 这种 task runner 其实更接近 build system，开发者使用这些 task runner 来手动编排文件的处理逻辑，以 task runner 作为 build system；同样的 turborepo 不关心任务逻辑，只执行任务，也声称自己是 build system。

Bundler 本身描述了一部分的任务逻辑，比如怎样构建模块、怎样拆分 chunk、怎样进行优化等，然后由用户的配置和插件提供剩余部分，组合成完整的 task descriptor。

### Bundler 和 Build system 的任务也是有些不同的：

首先 Bundler 任务的依赖是非常动态的（dynamic dependencies），任务逻辑本身是动态的，比如模块代码生成可能依赖于其他模块的生成结果、模块的优化可能依赖于其他模块的优化结果，而且用户的配置和插件也会影响任务逻辑，而早期 build system 对 dynamic dependencies 的支持并不好，基本都是静态依赖，比如 Make，到后来的 build system 才有了比较好的支持，比如 Shake、Buck2 等。

其次是对环的处理，Bundler 由于模块之间关系经常出现循环依赖关系，导致任务之间出现循环依赖，这时需要对环进行处理，而 build system 大部分都不支持环，当然也有少数 build system 对环进行了处理。

另外以 build system 中定义的 Build 为准的话，Bundler 的 Build 其实分为两种：

不中断 Compiler 的 Build，即 watch 下的 rebuild。

中断 Compiler 的 Build，即 build 完成后再次 build。

这两种 Build 也导致了两种不同的 Info，即 memory cache 和 persistent cache，这两种 Info 不仅能分开使用，也能针对场景进行混合使用。

### Webpack/Parcel/Rollup/esbuild

passBasedBundler = foreach ctRebuilder

在传统的 pass-based bundler 中，每个 pass 的任务执行顺序（Scheduler）和是否执行（Rebuilder）都是不同的，每个 pass 依据这个阶段的任务逻辑，使用适合这个阶段的任务执行顺序和是否执行策略，比如在 webpack 中：

module graph 和 chunk graph 并不是一个无环图，所以 topological scheduler 在大部分阶段都不适用。

SideEffectsFlagPlugin：在优化一个模块的 incoming connections 时，需要确保这个模块的父模块的 incoming connections 已经被优化过了，以达到最佳的优化效果，属于 suspending scheduler；但由于只是更新模块的 connection 关系，没有太大计算开销，所以没有任何逻辑来跳过任务的执行，属于 “always true” rebuilder。

FlagProvidedExportsPlugin：由于 re-export 会影响模块的导出内容，所以会将含有 re-export 模块和 re-export 引入模块记录为依赖关系，当 re-export 引入模块的导出内容改变时，会将含有 re-export 模块的导出内容重新进行计算，直到不再有模块的导出内容发生改变为止，属于 restarting scheduler；由于计算导出内容是有一定计算量的，所以引入了 cache 来跳过一些任务，属于 vtRebuilder。

其他大部分阶段的任务逻辑并不关心任务的先后顺序，比如 module build、module codegen 等，而且支持持久缓存，所以其他大部分 pass 都使用了 “foreach” scheduler + ctRebuilder 的组合。

在 pass-based bundler 中，cache 为 bundler 实现了 Minimality，但由于各个 pass 之间的任务互不感知，pass 之间的任务不能实现 early cutoff，导致仍然存在过量任务需要进行 cache 验证。这往往也是 pass-based bundler 慢的原因：没有实现 Early cutoff 导致不够 Minimality。

### Turbopack

turbopack = suspending ctRebuilder

不同于传统的 pass-based bundler，turbopack 并没有强调从头到尾的一个个编译阶段（pass），而是更接近于 query-based，定义任务，通过 query 获取任务结果，尤其是在 Dev 环境下，比如编译一个以 html 为入口的 web 页面，turbopack 的逻辑是：

图片

传统 pass-based bundler 的逻辑是：

图片

相比于 pass-based bundler，turbopack 只会关注获取 query 结果所需要执行的这一部分任务，其他无关任务不会执行，尤其 Dev 环境下不会有完整的 ModuleGraph 和 ChunkGraph。在 Production 环境下还是会通过一些方式来聚合成完整的图，以对完整 ModuleGraph / ChunkGraph 进行全局优化。

Turbopack 底层的 incremental computation engine：turbo tasks 就是驱动 turbopack 的 build system，task、scheduler、rebuilder 等 build system 的概念都有在 turbo tasks 中实现，上层 turbopack 相当于在 turbo tasks 的基础上对 bundler 的具体任务进行描述。这样看其实 incremental computation engine 本身就是一种 build system，同样基于 incremental computation engine：DICE 的 buck2 也类似，DICE 已经覆盖了 build system 中的核心功能，buck2 在其基础上实现将用户描述的任务作为 DICE 的任务进行执行。

图片

Turbopack 整体统一基于 turbo tasks，使用 suspending + ctRebuilder 的组合，实现整体的 Minimality 和 Early cutoff。

### Vite

vite = suspending vtRebuilder

虽然 Vite 本身并不会 Bundle，但 Vite 在 dev 时还是会对任务不断进行执行，符合 build system 的定义，Vite 并不会对多个模块进行打包，而是对单个模块进行编译，所以 Vite 的任务逻辑其实很简单，就是编译模块。Vite 是在浏览器对模块进行请求时才去编译模块，浏览器没命中缓存才会发起请求，发起请求的顺序就是模块 import 的顺序，也是由浏览器决定的，所以可以看出 Vite 利用浏览器 ESM 模块系统作为自己的一部分 build system，属于 suspending + vtRebuilder 的组合。

利用浏览器 ESM 模块系统虽然会让本身的实现简单很多，但浏览器 ESM 模块系统本身并不是以 build system 为目标来实现的，相比真正的 build system 会带来很多限制，比如：

请求并发数量被浏览器限制 ➡️ 任务并发数量除了任务的依赖关系、机器资源以外，额外被浏览器限制。

浏览器缓存不能共享 ➡️ 构建信息或任务缓存不能共享，浏览器限制 vtRebuilder 不能修改为 ctRebuilder。

### Rspack

incrementalRspack = foreach dirtyBitAndCtRebuilder

Rspack 本身也属于 pass-based bundler，但为了将 HMR 的性能从 O (project) 优化到 O (change)，Rspack 引入了 affected-based incremental。简单来说 affected-based incremental 会收集各个阶段的变更，后续阶段会根据收集到的变更计算出可能被影响的任务，从而只重新执行这些被影响的任务，减少任务的执行数量。

从 build system 的角度来讲，affected-based incremental 其实就是在 pass-based bundler 原有的 build system 基础上，引入新的 Rebuilder，让各个阶段之间的任务能够通过收集到的变更相互感知，以此能够对后续阶段的任务做 Early cutoff，通过添加 Early cutoff 这一特性来让 Rspack 更加 Minimality。这种方式更接近 self-adjusting computation：

The fundamental idea is to track the control and data dependencies in a computation in such a way that changes to data can be propagated through the computation by identifying the affected pieces that depend on the changes and re-doing the affected pieces. —— Self-Adjusting Computation

根据变更找到被影响的输入，作为 dirty 的输入重新执行对应任务，这种实现相比于 incremental computation 不那么智能，但却是一种相对简单且有效的方式。

# 前端构建系统概述

## 构建步骤

前端构建系统通常包括三个步骤：转译、打包和压缩。

有些应用程序可能不需要所有三个步骤。例如，较小的代码库可能不需要打包或压缩，开发服务器可能为了性能会跳过打包和 / 或压缩。还可以添加额外的自定义步骤。

某些工具实现了多个构建步骤。值得注意的是，打包器通常实现所有三个步骤，单独一个打包器就足以构建简单的应用程序。复杂的应用程序可能需要专门的工具来执行每个构建步骤，以提供更大的功能集。

## 转译

转译通过将用现代 JavaScript 标准编写的 JavaScript 转换为旧版 JavaScript 标准来解决不受支持的语言特性问题。如今，ES6/ES2015 是一个常见的目标。

框架和工具也可能引入转译步骤。例如，JSX 语法必须转译为 JavaScript。如果一个库提供了 Babel 插件，这通常意味着它需要一个转译步骤。此外，像 TypeScript、CoffeeScript 和 Elm 这样的语言也必须转译为 JavaScript。

CommonJS 模块（CJS）也必须转译为浏览器兼容的模块系统。自从 2018 年浏览器广泛支持 ES6 模块（ESM）以来，通常建议转译为 ESM。由于 ESM 的导入和导出是静态定义的，因此它更容易优化和 tree-shake 清理。

目前常用的转译器是 Babel、SWC 和 TypeScript 编译器。

Babel (2014) 是标准的转译器：一个用 JavaScript 编写的单线程转译器。许多需要转译的框架和库都通过 Babel 插件进行转译，因此 Babel 是构建过程中不可或缺的一部分。然而，Babel 很难调试，常常令人困惑。

SWC (2020) 是一个用 Rust 编写的快速多线程转译器。据称其速度比 Babel 快 20 倍；因此，它被较新的框架和构建工具所使用。它支持转译 TypeScript 和 JSX。如果你的应用程序不需要 Babel，那么 SWC 是一个更好的选择。

TypeScript 编译器 (tsc) 也支持转译 TypeScript 和 JSX。它是 TypeScript 的参考实现，也是唯一的全功能 TypeScript 类型检查器。然而，它非常慢。尽管 TypeScript 应用程序必须通过 TypeScript 编译器进行类型检查，但在构建步骤中，使用替代转译器会更高效。

如果你的代码是纯 JavaScript 并且使用 ES6 模块，则也可以跳过转译步骤。

对部分未得到支持的语言特性的替代解决方案是使用 “polyfill”。Polyfill 在运行时执行，实现任何缺失的语言特性，然后执行主应用程序逻辑。然而，这增加了运行时成本，并且某些语言特性无法通过 Polyfill 实现。参见 core-js。

所有打包器本质上也是转译器，因为它们解析多个 JavaScript 源文件并生成新的打包 JavaScript 文件。在这样做时，它们可以选择在其生成的 JavaScript 文件中使用哪些语言特性。某些打包器还能够解析 TypeScript 和 JSX 源文件。如果你的应用程序有简单的转译需求，则可能不需要单独的转译器。

## 打包

打包解决了需要进行大量网络请求和瀑布效应问题。打包器将多个 JavaScript 源文件连接成一个 JavaScript 输出文件，称为包，而不改变应用程序行为。包可以通过浏览器在一次往返网络请求中高效加载。

目前常用的打包器有 Webpack、Parcel、Rollup、esbuild 和 Turbopack。

Webpack (2014) 在 2016 年左右开始流行起来，后来成为标准打包器。与当时常用的与 Gulp 任务运行器一起使用的 Browserify 不同，Webpack 首创了在导入时转换源文件的 “加载器”，允许 Webpack 协调整个构建管道。

加载器允许开发者在 JavaScript 文件中透明地导入静态资源，将所有源文件和静态资源组合成一个依赖图。使用 Gulp 时，每种类型的静态资源必须作为单独的任务进行构建。Webpack 还支持开箱即用的代码分割，简化了其设置和配置。

Webpack 运行缓慢，单线程，用 JavaScript 编写。它高度可配置，但其许多配置选项可能令人困惑。

Rollup (2016) 利用 ES6 模块的广泛浏览器支持及其启用的优化（如 tree shaking），生成的包大小比 Webpack 小得多，从而导致 Webpack 之后采用了类似的优化。Rollup 是一个单线程打包器，用 JavaScript 编写，性能略优于 Webpack。

Parcel (2018) 是一个低配置的打包器，旨在开箱即用，为构建过程的所有步骤和开发工具需求提供合理的默认配置。它是多线程的，比 Webpack 和 Rollup 快得多。Parcel 2 在底层使用 SWC。

Esbuild (2020) 是一个为并行性和最佳性能而设计的打包器，用 Go 编写。其性能比 Webpack、Rollup 和 Parcel 高出数十倍。Esbuild 实现了一个基本的转译器和压缩器。然而，它的功能比其他打包器少，提供了一个有限的插件 API，无法直接修改 AST。与其通过 esbuild 插件修改源文件，不如在传递给 esbuild 之前对文件进行转换。

Turbopack (2022) 是一个支持增量重建的快速 Rust 打包器。该项目由 Vercel 构建，由 Webpack 的创作者领导。目前处于测试阶段，可以在 Next.js 中选择使用。

如果你只有很少的模块或网络延迟很低（例如在本地主机上），跳过打包步骤是合理的。几个开发服务器也选择不在开发服务器中打包模块。

## 代码分割

默认情况下，客户端 React 应用程序被转换成一个包。对于具有许多页面和功能的大型应用程序，包可能非常大，抵消了打包的原始性能优势。

将包划分为几个较小的包，即代码分割，可以解决这个问题。常见的方法是将每个页面分成一个单独的包。使用 HTTP/2，共享依赖项也可以被分解成它们自己的包，以避免重复，成本很低。此外，大模块可能会分割成一个单独的包并按需懒加载。

代码分割后，每个包的文件大小大大减少，但现在需要额外的网络往返，可能会重新引入瀑布问题。代码分割是一种权衡。

由 Next.js 推广的文件系统路由器优化了代码分割的权衡。Next.js 为每个页面创建单独的包，仅在其包中包含该页面导入的代码。加载一个页面会并行预加载该页面使用的所有包。这优化了包大小而不会重新引入瀑布问题。文件系统路由器通过为每个页面创建一个入口点（pages/**/*.jsx）来实现这一点，而不是传统客户端 React 应用程序的单一入口点（index.jsx）。

## Tree Shaking

一个包由多个模块组成，每个模块包含一个或多个导出。通常，一个包只使用其导入的模块的一部分导出。打包器可以通过一个称为 tree shake 的过程来移除模块的未使用导出。这优化了包大小，提高了加载和解析时间。

tree shaking 依赖于对源文件的静态分析，因此当静态分析变得更加困难时，tree shaking 的效率会受到影响。两个主要因素影响 tree shaking 的效率：

模块系统：ES6 模块具有静态导出和导入，而 CommonJS 模块具有动态导出和导入。因此，打包器在 tree shaking ES6 模块时能够更加积极和高效。

副作用：package.json 的 sideEffects 属性声明一个模块在导入时是否具有副作用。当存在副作用时，未使用的模块和未使用的导出可能不会被摇树，因为静态分析的局限性。

## 静态资源

静态资源，如 CSS、图像和字体，通常在打包步骤中添加到可分发文件中。它们也可能在压缩步骤中进行文件大小优化。

在 Webpack 之前，静态资源在构建管道中作为独立的构建任务与源代码分开构建。要加载静态资源，应用程序必须通过可分发文件中的最终路径引用它们。因此，通常会根据 URL 约定来仔细组织资产（例如 /assets/css/banner.jpg 和 /assets/fonts/Inter.woff2）。

Webpack 的 “加载器” 允许从 JavaScript 中导入静态资源，将代码和静态资源统一到一个依赖图中。在打包过程中，Webpack 将静态资源导入替换为其在可分发文件中的最终路径。这个功能使静态资源可以在源代码中与其关联的组件一起组织，并为静态分析创建了新的可能性，如检测不存在的资产。

需要注意的是，导入静态资源（非 JavaScript 或转译为 JavaScript 的文件）并不是 JavaScript 语言的一部分。它需要一个配置了对该资产类型支持的打包器。幸运的是，继 Webpack 之后的打包器也采用了 “加载器” 模式，使这个功能成为常态。

## 压缩

压缩解决了文件不必要过大的问题。压缩器在不影响文件行为的情况下减小文件大小。对于 JavaScript 代码和 CSS 资源，压缩器可以缩短变量名、消除空白和注释、消除死代码以及优化语言特性的使用。对于其他静态资源，压缩器可以执行文件大小优化。压缩器通常在构建过程的最后一步运行在包上。

目前常用的 JavaScript 压缩器有 Terser、esbuild 和 SWC。Terser 是从不维护的 uglify-es 分叉出来的。它用 JavaScript 编写，速度较慢。Esbuild 和 SWC 前面提到过，除了其他功能外，还实现了压缩器，并且比 Terser 快。

目前常用的 CSS 压缩器有 cssnano、csso 和 Lightning CSS。Cssnano 和 csso 是纯 CSS 压缩器，用 JavaScript 编写，速度较慢。Lightning CSS 用 Rust 编写，据称比 cssnano 快 100 倍。Lightning CSS 还支持 CSS 转换和打包。

## 元框架

前端领域以选择使用 “正确” 包的挑战而闻名。例如，列出的五个打包器中，应该选择哪一个？

元框架提供了一组精选的包，包括构建工具，它们协同工作并启用专门的应用程序范式。例如，Next.js 专注于服务器端渲染（SSR），Remix 专注于渐进增强。

元框架通常提供预配置的构建系统，免去了需要自己拼凑一个的麻烦。它们的构建系统同时为生产和开发服务器提供配置。

与元框架类似，构建工具如 Vite 提供预配置的构建系统，适用于生产和开发。不同的是，它们不强制要求特定的应用程序范式，适合一般的前端应用程序。

## 源映射

由构建管道生成的可分发文件对大多数人类来说是不可读的。这使得调试任何发生的错误变得困难，因为它们的回溯指向不可读的代码。

源映射通过将可分发文件中的代码映射回其在源代码中的原始位置来解决这个问题。浏览器和故障排除工具（例如 Sentry）使用源映射来恢复和显示原始源代码。在生产环境中，源映射通常隐藏在浏览器之外，仅上传到故障排除工具以避免公开源代码。

构建管道的每一步都可以生成源映射。如果使用多个构建工具构建管道，则源映射将形成一个链（例如 source.js -> transpiler.map -> bundler.map -> minifier.map）。要确定缩小代码对应的源代码，必须遍历源映射链。

然而，大多数工具无法解释源映射链；它们最多期望每个可分发文件有一个源映射。源映射链必须展平成一个单一的源映射。预配置的构建系统会解决这个问题（参见 Vite 的 combineSourcemaps 函数）。

## 热重载

开发服务器通常提供热重载功能，在源代码更改时自动重建新包并重新加载浏览器。尽管大大优于手动重建和重新加载，但仍然有些慢，所有客户端状态在重新加载时都会丢失。

热模块替换 改进了热重载，通过在运行的应用程序中替换更改的包进行就地更新。这样可以保留未更改模块的客户端状态，并减少代码更改和更新后的应用程序之间的延迟。

然而，每次代码更改都会触发所有导入它的包的重建。这导致相对于包大小的线性时间复杂度。因此，在大型应用程序中，热模块替换可能会由于重建成本的增加而变慢。

无包范式 目前由 Vite 倡导，通过不打包开发服务器来解决这一问题。相反，Vite 将每个源文件对应的 ESM 模块直接提供给浏览器。在这种范式中，每次代码更改只会触发前端的单个模块替换。结果是相对于应用程序大小几乎恒定的刷新时间复杂度。然而，如果你有很多模块，初始页面加载可能会更长。

## 单体代码库

在有多个团队或多个应用程序的组织中，前端可能会分成多个 JavaScript 包，但保存在一个仓库中。在这样的架构中，每个包都有自己的构建步骤，它们共同形成一个包的依赖图。应用程序位于依赖图的根部。

单体代码库工具协调依赖图的构建。它们通常提供增量重建、并行性和远程缓存等功能。通过这些功能，大型代码库可以享受小型代码库的构建时间。

更广泛的行业标准单体代码库工具如 Bazel 支持广泛的语言、复杂的构建图和封闭执行。然而，前端 JavaScript 是最难与这些工具完全集成的生态系统之一，目前几乎没有先例。

幸运的是，存在几种专门为前端设计的单体代码库工具。不幸的是，它们缺乏 Bazel 等的灵活性和鲁棒性，尤其是封闭执行。

目前常用的前端专用单体代码库工具是 Nx 和 Turborepo。Nx 更成熟，功能更多，而 Turborepo 是 Vercel 生态系统的一部分。过去，Lerna 是将多个 JavaScript 包链接在一起并将它们发布到 NPM 的标准工具。2022 年，Nx 团队接管了 Lerna，现在 Lerna 在底层使用 Nx 来驱动构建。

> 引用：https://mp.weixin.qq.com/s/felU4tIflAoazudcZnzt4g
> https://mp.weixin.qq.com/s?__biz=MjM5MTA1MjAxMQ==&mid=2651272340&idx=1&sn=6e4c00f27308616ad3e4da7fde5f268a&scene=21#wechat_redirect