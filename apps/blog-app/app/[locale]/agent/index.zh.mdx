# Agent

注意力机制
how to do attention

上下文向量

- 对齐函数


解决了RNN的问题
- 解决传统解码器-编码器的挑战，避免信息损失和无法建模输入输出对齐的问题
- 自动学习注意力权重，捕捉编码器和解码器之间的相关性。
- 构建上下文向量，使解码器能全面访问输入序列并重点关注相关部分。
- 提高模型性能，改善输出质量，并提供更好的解释性。

机器翻译的场景

Encoder-Decoder


